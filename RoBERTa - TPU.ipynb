{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1uedKqXll7IbJTxxtdX82ESNvP1Zy9vWa",
      "authorship_tag": "ABX9TyM57oOCA6xP5pB4Hjyo25oy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atherfawaz/BERT-Supervised/blob/master/RoBERTa%20-%20TPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ca7jIEhZNU_Q",
        "colab_type": "text"
      },
      "source": [
        "# Supervised Learning with BERT\n",
        "\n",
        "***Question*: Supervised Learning with BERT\n",
        "The Astrological department believes that a person's astrological sign can be guessed from their behavior. An organization is collecting blog-posts of different people from various sources. You have been tasked to build a Deep Learning model that can use these posts data of individuals to predict which star group out of 12 does an individual belong to. You also need to tell the gender of that person.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PIs-jEzMCT4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f62ef499-b2c1-48da-eee6-8b036447747c"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')\n",
        "%cd /content/drive/My Drive/Ebryx/blogs_train"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Ebryx/blogs_train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkiiBS5jEwkw",
        "colab_type": "text"
      },
      "source": [
        "# Unzip the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GW1LBluMU3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xvf  'blogs_train.tar.xz'\n",
        "%cd /content/drive/My Drive/Ebryx/blogs_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ArTrha5U1RA",
        "colab_type": "text"
      },
      "source": [
        "# Dataset\n",
        "The file name would contain the gender, age, occupation, and astrological sign of the blooger. For example, 4115891.male.24.Student.Leo.xml is one file. A single file will contain a set of blogs separated by date. To illustrate, this is what a sample file looks like:\n",
        "\n",
        "```\n",
        "<Blog>\n",
        "  <date>31,May,2004</date>\n",
        "    <post>\n",
        "      Well, everyone got up and going this morning.  It's still raining, but that's okay with me.  Sort of suits my mood.  I could easily have stayed home in bed with my book and the cats.  This has been a lot of rain though!..\n",
        "    </post>\n",
        "</Blog\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN1hRWkRd6vI",
        "colab_type": "text"
      },
      "source": [
        "# Parsing the dataset\n",
        "Parsing the dataset from separate files into a Pandas Dataframe for displaying and easy access. Some XML files contain encoding issues and the problematic contents of those files have been replaced by random number. While this could impact the accuracy of the model later, the effect would not be that big."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYh3rv4SnJ1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import codecs\n",
        "from bs4 import BeautifulSoup\n",
        "from progressbar import ProgressBar\n",
        "pbar = ProgressBar()\n",
        "\n",
        "print('PARSING FILES....')\n",
        "\n",
        "FILES = os.listdir()\n",
        "#print('File count: ', len(FILES))\n",
        "#print(FILES)\n",
        "#FILES = ['4115891.male.24.Student.Leo.xml', '4115958.male.16.Communications-Media.Libra.xml', '4116071.male.26.Arts.Sagittarius.xml', '4116243.female.24.Manufacturing.Sagittarius.xml']\n",
        "\n",
        "posts_arr = []\n",
        "sign_arr = []\n",
        "gender_arr = []\n",
        "age_arr = []\n",
        "occupation_arr = []\n",
        "\n",
        "for to_fetch in pbar(FILES):\n",
        "    #print('Parsing file:', to_fetch)\n",
        "    gender = to_fetch.split('.')[-5]\n",
        "    age = to_fetch.split('.')[-4]\n",
        "    occupation = to_fetch.split('.')[-3]\n",
        "    sign = to_fetch.split('.')[-2]\n",
        "    with codecs.open(to_fetch, 'r', encoding='utf-8', errors='ignore') as fp:\n",
        "      soup = BeautifulSoup(fp, 'lxml',\n",
        "                           from_encoding='utf8')\n",
        "      posts = soup.find_all('post')\n",
        "      #print(soup.prettify())\n",
        "      for post in posts:\n",
        "        clean_str = post.text\n",
        "        clean_str = clean_str.replace('\\r', '')\n",
        "        clean_str = clean_str.replace('\\n', '')\n",
        "        posts_arr.append(clean_str)\n",
        "        sign_arr.append(sign)\n",
        "        age_arr.append(age)\n",
        "        occupation_arr.append(occupation)\n",
        "        gender_arr.append(gender)\n",
        "\n",
        "df = pd.DataFrame({'Gender': gender_arr, 'Age': age_arr, 'Occupation': occupation_arr, 'Post': posts_arr, 'Sign': sign_arr})\n",
        "\n",
        "#df.head(50)\n",
        "df.to_csv('/content/drive/My Drive/Ebryx/dataset.csv', encoding='utf-8', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjGpg5ZfnmcH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head(100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knjTjaAtcx-H",
        "colab_type": "text"
      },
      "source": [
        "# Loading BERT for finetuning\n",
        "\n",
        "Taking help from the model implementation from huggingface and [this repository](https://colab.research.google.com/github/abhimishra91/transformers-tutorials/blob/master/transformers_multiclass_classification.ipynb#scrollTo=JrBr2YesGdO_).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKyIOfh5jmCz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "outputId": "ff009bb9-bcfd-4966-97f2-341dccf53da0"
      },
      "source": [
        "!pip install transformers;"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 23.0MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 27.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 29.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=41324aac1e70f81848fb404b852c263ed7d12e52fa0f480356ee67fc7f9f59b6\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32pVsuaBj12B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "f4277908-167f-467f-df80-ff28f6ab2d41"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Aug 25 05:26:46 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkjgmBG-jHPs",
        "colab_type": "text"
      },
      "source": [
        "# Setting up training environment, imports, and hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtI3Pfx5Maj1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 995
        },
        "outputId": "3242e4bc-f6fe-48f1-affd-4764bf8a1b76"
      },
      "source": [
        "# Code for TPU packages install\n",
        "!curl -q https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "!python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  5115  100  5115    0     0  12092      0 --:--:-- --:--:-- --:--:-- 12092\n",
            "Updating... This may take around 2 minutes.\n",
            "Uninstalling torch-1.6.0+cu101:\n",
            "  Successfully uninstalled torch-1.6.0+cu101\n",
            "Uninstalling torchvision-0.7.0+cu101:\n",
            "  Successfully uninstalled torchvision-0.7.0+cu101\n",
            "Copying gs://tpu-pytorch/wheels/torch-nightly+20200515-cp36-cp36m-linux_x86_64.whl...\n",
            "\\ [1 files][ 91.0 MiB/ 91.0 MiB]                                                \n",
            "Operation completed over 1 objects/91.0 MiB.                                     \n",
            "Copying gs://tpu-pytorch/wheels/torch_xla-nightly+20200515-cp36-cp36m-linux_x86_64.whl...\n",
            "\\ [1 files][119.5 MiB/119.5 MiB]                                                \n",
            "Operation completed over 1 objects/119.5 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torchvision-nightly+20200515-cp36-cp36m-linux_x86_64.whl...\n",
            "/ [1 files][  2.3 MiB/  2.3 MiB]                                                \n",
            "Operation completed over 1 objects/2.3 MiB.                                      \n",
            "Processing ./torch-nightly+20200515-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200515) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200515) (0.16.0)\n",
            "\u001b[31mERROR: fastai 1.0.61 requires torchvision, which is not installed.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-1.6.0a0+bf2bbd9\n",
            "Processing ./torch_xla-nightly+20200515-cp36-cp36m-linux_x86_64.whl\n",
            "Installing collected packages: torch-xla\n",
            "Successfully installed torch-xla-1.6+2b2085a\n",
            "Processing ./torchvision-nightly+20200515-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200515) (1.18.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200515) (1.6.0a0+bf2bbd9)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200515) (7.0.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision==nightly+20200515) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.7.0a0+a6073f0\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libopenblas-dev is already the newest version (0.2.20+ds-4).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  libomp5\n",
            "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 234 kB of archives.\n",
            "After this operation, 774 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
            "Fetched 234 kB in 1s (276 kB/s)\n",
            "Selecting previously unselected package libomp5:amd64.\n",
            "(Reading database ... 144487 files and directories currently installed.)\n",
            "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
            "Setting up libomp5:amd64 (5.0.1-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7amTtuAjhZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing the libraries needed\n",
        "# Importing stock ml libraries\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "import transformers\n",
        "from sklearn.utils import shuffle\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import DistilBertModel, DistilBertTokenizer\n",
        "from progressbar import ProgressBar\n",
        "pbar = ProgressBar()\n",
        "\n",
        "# Defining some key variables that will be used later on in the training\n",
        "MAX_LEN = 512\n",
        "TRAIN_BATCH_SIZE = 32\n",
        "VALID_BATCH_SIZE = 4\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 1e-05\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased')\n",
        "\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHlE5CcWoaNW",
        "colab_type": "text"
      },
      "source": [
        "# Loading dataset from CSV\n",
        "\n",
        "Converted the class labels into a one-hot encoded format to signify zodiac sign plus gender."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBPNbR2tl8sZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "779483e1-e961-401c-fc66-9ea2c7141a02"
      },
      "source": [
        "# Creating the dataset and dataloader for the neural network\n",
        "df = pd.read_csv('/content/drive/My Drive/Ebryx/dataset.csv')\n",
        "df = df[['Post', 'Sign', 'Gender']]\n",
        "\n",
        "encode_dict = {}\n",
        "\n",
        "def encode_cat(x):\n",
        "    if x not in encode_dict.keys():\n",
        "      encode_dict[x]=len(encode_dict)\n",
        "    return encode_dict[x]\n",
        "\n",
        "df['Sign'] = df['Sign'].apply(lambda x: encode_cat(x))\n",
        "df['Post'] = df['Post'].str.replace('\\r','').str.replace('\\t','').str.replace('\\xa0', '')\n",
        "\n",
        "df = df [['Post', 'Sign']]\n",
        "\n",
        "df = shuffle(df)\n",
        "df.head(10)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Post</th>\n",
              "      <th>Sign</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>282230</th>\n",
              "      <td>I also enjoyed the writer's circl...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196254</th>\n",
              "      <td>really i thought i finally had this fig...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354149</th>\n",
              "      <td>Victims aren't we all  Woke up this mo...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46474</th>\n",
              "      <td>I am back...I have this great urge to b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>315440</th>\n",
              "      <td>This morning I walked around the ...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191281</th>\n",
              "      <td>Best Film I Saw in 2003:    Da Return ...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>283583</th>\n",
              "      <td>I got to thinking about what makes a TV...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>184039</th>\n",
              "      <td>.~*~.      LOOK OUT!   ïòð      Sasha i...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1397</th>\n",
              "      <td>why?  I have been trying to post ...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68426</th>\n",
              "      <td>It just bites the big one that I can't ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     Post  Sign\n",
              "282230               I also enjoyed the writer's circl...    11\n",
              "196254         really i thought i finally had this fig...     8\n",
              "354149          Victims aren't we all  Woke up this mo...     8\n",
              "46474          I am back...I have this great urge to b...     0\n",
              "315440               This morning I walked around the ...    10\n",
              "191281          Best Film I Saw in 2003:    Da Return ...     9\n",
              "283583         I got to thinking about what makes a TV...    10\n",
              "184039         .~*~.      LOOK OUT!   ïòð      Sasha i...     4\n",
              "1397                 why?  I have been trying to post ...     8\n",
              "68426          It just bites the big one that I can't ...     1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NT4MFsu3kW8h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "49a96928-1277-4bb3-8ad9-cac01e51164b"
      },
      "source": [
        "class Triage(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        post = str(self.data.Post[index])\n",
        "        post = \" \".join(post.split())\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            post,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'targets': torch.tensor(self.data.Sign[index], dtype=torch.long)\n",
        "        } \n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "# Creating the dataset and dataloader for the neural network\n",
        "\n",
        "train_size = 0.8\n",
        "train_dataset=df.sample(frac=train_size,random_state=200)\n",
        "test_dataset=df.drop(train_dataset.index).reset_index(drop=True)\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(df.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "training_set = Triage(train_dataset, tokenizer, MAX_LEN)\n",
        "testing_set = Triage(test_dataset, tokenizer, MAX_LEN)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FULL Dataset: (380720, 2)\n",
            "TRAIN Dataset: (304576, 2)\n",
            "TEST Dataset: (76144, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNFZh2WQkhl5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YB0uZ-dgnJm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model. \n",
        "\n",
        "class DistillBERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DistillBERTClass, self).__init__()\n",
        "        self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
        "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "        self.classifier = torch.nn.Linear(768, 12)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden_state = output_1[0]\n",
        "        pooler = hidden_state[:, 0]\n",
        "        pooler = self.pre_classifier(pooler)\n",
        "        pooler = torch.nn.ReLU()(pooler)\n",
        "        pooler = self.dropout(pooler)\n",
        "        output = self.classifier(pooler)\n",
        "        return output\n",
        "\n",
        "model = DistillBERTClass()\n",
        "model.to(device)\n",
        "\n",
        "# Creating the loss function and optimizer\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwhi-s_AnR4K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "outputId": "5e498724-93ff-478d-8756-9415d33ea582"
      },
      "source": [
        "# Function to calcuate the accuracy of the model\n",
        "\n",
        "def calcuate_accu(big_idx, targets):\n",
        "    n_correct = (big_idx==targets).sum().item()\n",
        "    return n_correct\n",
        "\n",
        "# Defining the training function on the 80% of the dataset for tuning the distilbert model\n",
        "\n",
        "def train(epoch):\n",
        "    tr_loss = 0\n",
        "    n_correct = 0\n",
        "    nb_tr_steps = 0\n",
        "    nb_tr_examples = 0\n",
        "    model.train()\n",
        "    for i,data in enumerate(training_loader, 0):\n",
        "        ids = data['ids'].to(device, dtype = torch.long)\n",
        "        mask = data['mask'].to(device, dtype = torch.long)\n",
        "        targets = data['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "        outputs = model(ids, mask)\n",
        "        loss = loss_function(outputs, targets)\n",
        "        tr_loss += loss.item()\n",
        "        big_val, big_idx = torch.max(outputs.data, dim=1)\n",
        "        n_correct += calcuate_accu(big_idx, targets)\n",
        "\n",
        "        nb_tr_steps += 1\n",
        "        nb_tr_examples+=targets.size(0)\n",
        "        \n",
        "        if i%5==0:\n",
        "            loss_step = tr_loss/nb_tr_steps\n",
        "            accu_step = (n_correct*100)/nb_tr_examples \n",
        "            print(f\"[ {i} ] Loss: {loss_step:.3f} | Accuracy: {accu_step:.3f}\")\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        # # When using GPU\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n",
        "    epoch_loss = tr_loss/nb_tr_steps\n",
        "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
        "    print(f\"Training Loss Epoch: {epoch_loss}\")\n",
        "    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n",
        "\n",
        "    return \n",
        "\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    train(epoch)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0 ] Loss: 2.498 | Accuracy: 6.250\n",
            "[ 5 ] Loss: 2.491 | Accuracy: 9.375\n",
            "[ 10 ] Loss: 2.491 | Accuracy: 7.670\n",
            "[ 15 ] Loss: 2.488 | Accuracy: 7.812\n",
            "[ 20 ] Loss: 2.487 | Accuracy: 7.440\n",
            "[ 25 ] Loss: 2.488 | Accuracy: 8.534\n",
            "[ 30 ] Loss: 2.490 | Accuracy: 8.165\n",
            "[ 35 ] Loss: 2.489 | Accuracy: 8.420\n",
            "[ 40 ] Loss: 2.490 | Accuracy: 8.384\n",
            "[ 45 ] Loss: 2.488 | Accuracy: 8.628\n",
            "[ 50 ] Loss: 2.488 | Accuracy: 8.762\n",
            "[ 55 ] Loss: 2.488 | Accuracy: 8.426\n",
            "[ 60 ] Loss: 2.488 | Accuracy: 8.402\n",
            "[ 65 ] Loss: 2.488 | Accuracy: 8.333\n",
            "[ 70 ] Loss: 2.487 | Accuracy: 8.451\n",
            "[ 75 ] Loss: 2.486 | Accuracy: 8.717\n",
            "[ 80 ] Loss: 2.484 | Accuracy: 8.873\n",
            "[ 85 ] Loss: 2.484 | Accuracy: 8.757\n",
            "[ 90 ] Loss: 2.484 | Accuracy: 8.791\n",
            "[ 95 ] Loss: 2.484 | Accuracy: 8.757\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-0009ec4d398e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-0009ec4d398e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mbig_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbig_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mn_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcalcuate_accu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbig_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4WHyM1F-Lys",
        "colab_type": "text"
      },
      "source": [
        "# Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8AbHlN6pra_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validation(epoch):\n",
        "    model.eval()\n",
        "    fin_targets=[]\n",
        "    fin_outputs=[]\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(testing_loader, 0):\n",
        "            ids = data['ids'].to(device, dtype = torch.long)\n",
        "            mask = data['mask'].to(device, dtype = torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "            targets = data['targets'].to(device, dtype = torch.float)\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "    return fin_outputs, fin_targets\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    outputs, targets = validation(epoch)\n",
        "    outputs = np.array(outputs) >= 0.5\n",
        "    accuracy = metrics.accuracy_score(targets, outputs)\n",
        "    f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
        "    f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
        "    print(f\"Accuracy Score = {accuracy}\")\n",
        "    print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
        "    print(f\"F1 Score (Macro) = {f1_score_macro}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}